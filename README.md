

# ğŸ§  Prostate Cancer Segmentation â€” Fine-Tuning Segment Anything (SAM)

This repository contains a full pipeline to **fine-tune the Segment Anything Model (SAM)** on the **PANDA â€“ Prostate Cancer Grade Assessment** dataset.
The objective is to adapt SAM (originally trained on natural images) to perform **medical image segmentation** on prostate histopathology slides.

The project includes:

* ğŸ§¬ A complete training pipeline
* âš™ï¸ Automated checkpointing + interruption-safe saving
* ğŸ“ Config files, logs, and summaries for full reproducibility
* ğŸ“Š Loss tracking and visualization
* ğŸ“‚ Clean, production-ready project structure
* â˜ï¸ Notebook for Colab / Kaggle training

---

## ğŸ“‚ Project Structure

```
prostate-cancer-finetuning/
â”‚
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ fine_tune_model.ipynb        # Main training notebook
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ utils.py                     # Custom dataset, transforms, helpers
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ .gitkeep                     # Placeholder (dataset not included)
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ backup_epoch1_batch800.pt    # Auto-saved checkpoint  
â”‚   â”œâ”€â”€ model.pt                     # Final / interrupted model (large file â€“ optional)
â”‚   â”œâ”€â”€ model_config.yaml            # Auto-generated SAM model config  
â”‚   â”œâ”€â”€ results_summary.md           # Auto summary of training  
â”‚   â”œâ”€â”€ training_config.json         # All training hyperparameters  
â”‚   â””â”€â”€ training_log.txt             # Full training logs  
â”‚
â”œâ”€â”€ requirements.txt                 # Environment dependencies
â”œâ”€â”€ LICENSE                          # MIT License
â””â”€â”€ README.md                        # Project documentation
```

---

## ğŸ“Š Dataset Details

### ğŸ§ª Dataset Used

**PANDA â€“ Prostate Cancer Grade Assessment (Resized 512Ã—512)**
ğŸ“Œ Source: [Kaggle Dataset â€” PANDA Resized](https://www.kaggle.com/datasets/xhlulu/panda-resized-train-data-512x512)

The dataset contains:

* Histopathology slide tiles (512Ã—512)
* Segmentation masks
* Balanced cancer grade distribution

---

## ğŸ”§ Model & Training

### ğŸ§  Model

* **Base model:** Segment Anything Model (SAM) by Meta AI
* **Fine-tuned variant:** MedSAM / SAM-ViT-B
* **Framework:** PyTorch
* **Training type:** Batch training (batch size = 2)

### ğŸš€ Training Features

* Automatic **model checkpointing** every N batches
* **Epoch-wise saving** (`model_epoch_X.pt`)
* **KeyboardInterrupt-safe saving** â†’ creates `interrupted_model.pt`
* **Crash-safe saving** â†’ creates `crashed_model.pt`
* Logs saved to:
  âœ” `training_log.txt`
  âœ” `training_config.json`
* Auto-generated:
  âœ” `model_config.yaml`
  âœ” `results_summary.md`

### ğŸ“‰ Loss Curve

A loss curve (`loss_curve.png`) is generated automatically when training completes.
If interrupted early, you can manually regenerate it using the saved logs.

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/Amrisha-Bhardwaj1/prostate-cancer-finetuning.git
cd prostate-cancer-finetuning
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Download dataset (Kaggle)

```bash
kaggle datasets download -d xhlulu/panda-resized-train-data-512x512
unzip panda-resized-train-data-512x512.zip -d ./data
```

---

## ğŸš€ Run the Training

Open notebook:

```bash
jupyter notebook notebook/fine_tune_model.ipynb
```

Or use Google Colab / Kaggle.

The training loop supports:

* Slow GPU environments
* Manual stopping (Ctrl + M â†’ I in Colab)
* Automatic recovery

---

## ğŸ§¾ Output Files (Important for Reproducibility)

| File                                | Description                            |
| ----------------------------------- | -------------------------------------- |
| **training_config.json**            | Hyperparameters & environment settings |
| **training_log.txt**                | Per-batch & per-epoch logs             |
| **loss_curve.png**                  | Loss trend over epochs                 |
| **model_config.yaml**               | Model architecture/config dump         |
| **results_summary.md**              | Summary of saved checkpoints           |
| **model.pt / interrupted_model.pt** | Final or interrupted model weights     |
| **backup_epochX_batchY.pt**         | Periodic batch-level checkpoints       |

âœ” Push all `.json`, `.txt`, `.png`, `.yaml`, `.md` to GitHub
âœ” Model `.pt` files **are optional** because they are large

---

## ğŸ§‘â€ğŸ’» Author

**Amrisha Bhardwaj**
M.Tech | Computer Science, NIT Bhopal
ğŸ”— GitHub: [https://github.com/Amrisha-Bhardwaj1](https://github.com/Amrisha-Bhardwaj1)

---
